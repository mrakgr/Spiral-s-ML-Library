// The transposing loop module.

open corebase
open tensorm
open tensor_cuda
open rangem

// Replaces the free variables in the first argument with those in the second one.
// Both of them have to have the same number of free variables and the pairs of them have to have equal type.
inl free_vars_replace forall a b. (a : a) (b : b) : a = !!!!FreeVarsReplace(a,b)

// Uses a shared tensor to transpose all the free variables in shared memory before running the function.
// Uses a projective loop under the hood.
// The return value from the given function should be the same for every thread in the output dimension.
// If not, the results are undefined.
inl projective forall dim t. (dim : dim) (f : int -> dim -> t) : t =
    inl body forall el. (fv : el) : t = 
        inl shared_in : tensor int el = tensor_create_shared threads_per_block()
        inl shared_out : tensor int t = tensor_create_shared threads_per_block()
        tensor_set thread_index() fv shared_in
        barrier_cta_sync 0
        loop.projective threads_in_block(threads_per_block(), dim) fun thread_id, dim =>
            tensor_set thread_id
                (free_vars_replace f (tensor_index thread_id shared_in) thread_id dim)
                shared_out
        barrier_cta_sync 0
        tensor_index thread_index() shared_out
    real
        open real_core
        inl fv = free_vars f
        body `(`fv) fv

// Uses a shared tensor to transpose all the free variables in shared memory before running the function.
// Uses a (restrictive) linear loop under the hood.
// The inner dimension must be divisible by the number of threads per block.
// The return value from the given function should be the same for every thread in the output dimension.
// If not, the results are undefined.
inl linear forall dim t. (dim_inner : dim) (f : int -> dim -> t) : t =
    inl body forall el. (fv : el) : t = 
        inl shared_in : tensor int el = tensor_create_shared threads_per_block()
        inl shared_out : tensor int t = tensor_create_shared threads_per_block()
        tensor_set thread_index() fv shared_in
        barrier_cta_sync 0

        inl (dim_block,dim_inner),(dim_block',dim_inner') = loop.rigid_split threads_per_block() (shared_in.dim, dim_inner)
        assert (loop.prod dim_inner' = 1) "The threads per block need to be divisible by the inner dimension."
        inl index_block,index_inner = loop.proj (dim_block,dim_inner) thread_index()
        inl shared_in = reshape const(dim_block',dim_block) shared_in |> reorder (fun dim_block',dim_block => dim_block,dim_block') |> apply index_block
        loop.linear dim_block' fun index_block' =>
            // Calculate the local thread id.
            inl thread_id =
                inl dim = dim_block, dim_block'
                inl index = index_block, index_block'
                loop.rigid_merge dim index
            tensor_set thread_id
                (free_vars_replace f (tensor_index index_block' shared_in) thread_id index_inner)
                shared_out
        barrier_cta_sync 0
        tensor_index thread_index() shared_out
    real
        open real_core
        inl fv = free_vars f
        body `(`fv) fv