open game
open corebase
open corecuda
open coreext

union player_type = Computer | Random
type player_types = sam.sa 2 player_type

union event =
    | StartTraining : sam.sa 2 player_type

type state_neural =
    {
        model_data : ml.layers.model_data
    }

type state =
    {
        neural : state_neural
    }

inl init() : state = 
    {
        neural = {
            model_data = model.game_graph() |> ml.cfr_models.init |> ml.cfr_models.to_model_data
        }
    }

type state_internal =
    {
        pl_type : refm.ref player_types
        deck : refm.ref deck
        messages : refm.ref messages
        rng : refm.ref random.philox_state
    }

// Converts the given state to internal one.
// The refs will point to the original locations.
inl state_to_internal pl_type : state_internal =
    {
        pl_type = refm.from_local pl_type
        deck = refm.from_local deckm.create()
        messages = refm.from_local sa_create
        rng = random.init {seed = $"clock64()"; subsequence=conv rangem.threads_in_grid().from; offset=0}
    }

type rewards = sam.sa 2 ml.cfr.reward

inl play_loop (cfr_model : ml.cfr_models.cfr_game_model _ _) (state : state_internal) ~node : rewards = join
    inl rewards : rewards = sa_create
    inl set_rewards winner_id (chips_won : int) =
        inl chips_won = conv chips_won
        set rewards winner_id chips_won
        set rewards (toggle winner_id) -chips_won
    inl push_message = sa_listm.push (refm.to_local state.messages)
    inl pop_deck () = 
        open refm
        inl c,d = deckm.draw_card state.rng #state.deck
        state.deck <-# d
        c

    inl body node =
        open refm
        match node with
        | TerminalFold table =>
            inl msg = 
                inl chips_won = index table.pot table.player_turn
                set_rewards table.player_turn -chips_won
                Showdown{cards_shown=table.pl_card; chips_won winner_id=toggle table.player_turn}
            push_message msg
            None
        | TerminalCall table =>
            inl msg =
                inl chips_won, winner_id =
                    inl chips_won = index table.pot table.player_turn
                    match compare_hands table with
                    | Gt => chips_won, 0
                    | Eq => 0, -1
                    | Lt => chips_won, 1
                set_rewards (abs winner_id) chips_won
                Showdown{cards_shown=table.pl_card; chips_won winner_id}
            push_message msg
            None
        | Round table => 
            match index #state.pl_type table.player_turn with
            | Computer =>
                open model
                inl data = table, refm.to_local state.messages
                inl action = ml.cfr_models.trace_and_play state.rng cfr_model ({player_id=table.player_turn}, data) |> action_conv table
                inl msg = PlayerAction(table.player_turn, action)
                push_message msg
                Some (game_round table action)
            | Random =>
                inl action = random_action state.rng table
                inl msg = PlayerAction(table.player_turn, action)
                push_message msg
                Some (game_round table action)
        | RoundWithAction(table,action) =>
            inl msg = PlayerAction(table.player_turn, action)
            push_message msg
            Some (game_round table action)
        | ChanceCommunityCard table =>
            inl card = pop_deck()
            inl msg = CommunityCardIs card
            push_message msg
            Some (game_chance_community_card table card)
        | ChanceInit () => 
            inl c0,c1 = pop_deck(), pop_deck()
            push_message PlayerGotCard(0, c0)
            push_message PlayerGotCard(1, c1)
            Some (game_chance_init (c0,c1))
    
    loop.while (function Some => true | None => false) (optionm.bind body) (Some node) |> ignore

    rewards

inl event_loop state_neural (msg : event) =
    open refm
    match msg with
    | StartTraining config =>
        inl state_internal = state_to_internal config
        play_loop state_neural state_internal game_init()

open corecuda
open corepython
open coreext
inl main() =
    named_tuple "Leduc_Game" {
        init = fun () => jsonm.serialize init()
        event_loop_gpu = fun (msg, state : _ event * _ state) =>
            open serializer
            inl seri = {
                msg = create_serializer
            }
            serialize seri.msg (jsonm.deserialize msg)
            inl {neural} = jsonm.deserialize state

            console.write_ln "Going to run the Leduc training kernel."
            global "import time"
            inl p : f64 = $"time.perf_counter()"

            run' {shared_mem=model.game_graph() |> ml.cfr_models.smem_used} fun () =>
                inl model = ml.cfr_models.from_model_data model.game_graph() neural.model_data
                inl grid = cooperative_groups.create_grid()
                loop.linear (1 <<< 2) fun (_ : int) =>
                    loop.linear (1 <<< 3) fun (_ : int) =>
                        // When converting the state to internal form, the refs will point to the original.
                        event_loop model (deserialize seri.msg)
                        |> ml.cfr_models.calculate_updates model
                    
                    ml.cfr_models.apply_updates grid model

            inl p2 : f64 = $"time.perf_counter()"
            console.write "The time it took to run the kernel (in seconds) is: "
            console.write_ln (p2 - p)

            jsonm.serialize { neural }
    }