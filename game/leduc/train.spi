open game
open corebase
open corecuda
open coreext

union player_type = Computer | Random
type player_types = sam.sa 2 player_type

union event =
    | StartTraining : sam.sa 2 player_type

type state_neural =
    {
        model_data : ml.layers.model_data
    }

type state =
    {
        neural : state_neural
    }

inl init() : state = 
    {
        neural = {
            model_data = model.game_graph() |> ml.cfr_models.init |> ml.cfr_models.to_model_data
        }
    }

type state_internal =
    {
        pl_type : refm.ref player_types
        deck : refm.ref deck
        messages : refm.ref messages
        rng : refm.ref random.philox_state
    }

// Converts the given state to internal one.
// The refs will point to the original locations.
inl state_to_internal pl_type : state_internal =
    {
        pl_type = refm.from_local pl_type
        deck = refm.from_local deckm.create()
        messages = refm.from_local sa_create
        rng = random.init {seed = $"clock64()"; subsequence=conv rangem.threads_in_grid().from; offset=0}
    }

let play_loop (neural : state_neural) (state : state_internal) node =
    inl push_message = sa_listm.push (refm.to_local state.messages)
    inl pop_deck () = 
        open refm
        inl c,d = deckm.draw_card state.rng #state.deck
        state.deck <-# d
        c

    inl body node =
        open refm
        match node with
        | TerminalFold table =>
            inl msg = 
                inl chips_won = index table.pot table.player_turn
                Showdown{cards_shown=table.pl_card; chips_won winner_id=toggle table.player_turn}
            push_message msg
            // TODO: Should have an optimization effect. Maybe return the reward?
            None
        | TerminalCall table =>
            inl msg =
                inl chips_won, winner_id =
                    inl chips_won = index table.pot table.player_turn
                    match compare_hands table with
                    | Gt => chips_won, 0
                    | Eq => 0, -1
                    | Lt => chips_won, 1
                Showdown{cards_shown=table.pl_card; chips_won winner_id}
            push_message msg
            // TODO: Should have an optimization effect. Maybe return the reward?
            None
        | Round table => 
            match index #state.pl_type table.player_turn with
            | Computer =>
                open model
                inl model = ml.cfr_models.from_model_data model.game_graph() neural.model_data
                inl data = table, refm.to_local state.messages
                inl action = ml.cfr_models.run model (Some data) |> action_conv table
                inl msg = PlayerAction(table.player_turn, action)
                push_message msg
                Some (game_round table action)
            | Random =>
                inl action = random_action state.rng table
                inl msg = PlayerAction(table.player_turn, action)
                push_message msg
                Some (game_round table action)
        | RoundWithAction(table,action) => 
            inl msg = PlayerAction(table.player_turn, action)
            push_message msg
            Some (game_round table action)
        | ChanceCommunityCard table =>
            inl card = pop_deck()
            inl msg = CommunityCardIs card
            push_message msg
            Some (game_chance_community_card table card)
        | ChanceInit () => 
            inl c0,c1 = pop_deck(), pop_deck()
            push_message PlayerGotCard(0, c0)
            push_message PlayerGotCard(1, c1)
            Some (game_chance_init (c0,c1))
    
    loop.while (function Some => true | None => false) (optionm.bind body) (Some node) |> ignore

inl event_loop state_neural (msg : event) : () =
    open refm
    match msg with
    | StartTraining config =>
        inl state_internal = state_to_internal config
        play_loop state_neural state_internal game_init()

open corecuda
open corepython
open coreext
inl main() =
    named_tuple "Leduc_Game" {
        init = fun () => jsonm.serialize init()
        event_loop_gpu = fun (msg, state : _ event * _ state) =>
            open serializer
            inl seri = {
                msg = create_serializer
            }
            serialize seri.msg (jsonm.deserialize msg)
            inl {neural} = jsonm.deserialize state

            console.write_ln "Going to run the Leduc training kernel."
            global "import time"
            inl p : f64 = $"time.perf_counter()"

            run' {shared_mem=model.game_graph() |> ml.cfr_models.smem_used} fun () =>
                inl c : _ int = refm.create_shared_var (const threads_per_block())

                // When converting the state to internal form, the refs will point to the original.
                event_loop neural (deserialize seri.msg)

                // nn model loop
                intrinsic.atomic_add_ref c -1 |> ignore
                loop.while' (const true) fun () =>
                    inl model = ml.cfr_models.from_model_data model.game_graph() neural.model_data
                    ml.cfr_models.run model None |> ignore
                    if refm.deref c = 0 then loop.break()

            inl p2 : f64 = $"time.perf_counter()"
            console.write "The time it took to run the kernel (in seconds) is: "
            console.write_ln (p2 - p)

            jsonm.serialize {
                neural
                }
    }