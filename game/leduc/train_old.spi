// open corebase
// open corepython

// type plist t = plistm.plist t
// type public_state = 
//     {
//         training_iterations : int
//     }

// type leduc_train_label = string
// type leduc_train_serie =
//     {
//         name : string
//         data : plist float
//     }

// union train_events =
//     | Train : public_state

// union ui_effect =
//     | GraphAddItem : plist leduc_train_label * plist leduc_train_serie

// type private_state =
//     {
//         // empty for now
//     }

// type state = {private_state : private_state; public_state : public_state}

// open corecuda
// open corepython

// inl pu_history() : pickler.pu history =
//     open pickler
//     inl card : pu card = alt {
//         King = unit()
//         Queen = unit()
//         Jack = unit()
//     }
//     inl action : pu action = alt {
//         Fold = unit()
//         Call = unit()
//         Raise = unit()
//     }
//     inl action_or_card : pu (choice2 action card) = action ++ card
//     inl history : pu history = sa_list action_or_card
//     history

// inl graph() =
//     inl size = {
//         ensemble = 4 // The third dimension of each weight layer.
//         block = blocks_per_grid()
//         minibatch = 16 // threads_per_block()
//         inner = modup pu_history.size 128
//     }

//     inl graph =
//         (input .input (size.block,size.minibatch,size.inner) : graph (tensor (int * int * int) float))
//         |> apply .block
//         |> matmul_ensemble (size.ensemble,size.inner,size.inner)
//         |> ln_l2
//         |> relu
//         |> matmul_ensemble (size.ensemble,size.inner,size.inner)
//         |> ln_l2
//         |> relu
//         |> matmul_ensemble (size.ensemble,size.inner,size.inner)
//         |> softmax_and_discrete_sample' (input .output_indices (size.block,size.ensemble,size.minibatch) |> apply .block |> apply .ensemble)

//     graph

// inl main() =
//     named_tuple "Leduc_Train" {
//         init = fun () => 
//             jsonm.serialize {
//                 private_state =
//                     {
//                         // nn model
//                         // tensor of model rewards
//                     } : private_state
//                 public_state = 
//                     {
//                         training_iterations = 100
//                     } : public_state
//             }
            
//         event_loop_gpu = fun (msg, state : jsonm.json train_events * jsonm.json state) =>
//             open serializer
//             inl seri = {
//                 msg = create_serializer
//                 public_state = create_serializer
//             }
//             inl msg, state = jsonm.deserialize msg, jsonm.deserialize state
//             serialize seri.msg msg
//             serialize seri.public_state state.public_state

//             // need the NN model
//             run fun () =>
//                 // we'll destruct the Train msg here.
//                 // we'll implement the train loop without the capability to play against the AI agent.
//                 // that will come later.
//                 // inl game_state = event_loop (deserialize seri.msg, deserialize seri.game_state)
//                 // serialize seri.game_state game_state
//                 // serialize seri.ui_state (game_to_ui game_state)
//                 ()

//             // jsonm.serialize {
//             //     game_state = deserialize seri.game_state
//             //     ui_state = deserialize seri.ui_state
//             // }
            
//     }