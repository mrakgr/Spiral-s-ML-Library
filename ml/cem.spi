open corebase
open corecuda
open coreext
open primitives

type prob = float
type log_prob = f64
type ensemble_id = int
type player_id = int
type action_id = int
type thread_id = int
type seq_id = int
type action_prob = {sampling : prob; policy : prob}
type log_path_prob = {sampling : log_prob; policy : log_prob}
type reward = float
type count = float
type ratio = reward * count

type sizes =
    {
        ensemble_id : ensemble_id
        player_id : player_id
        action_id : action_id
        number_of_valid_actions : action_id
        thread_id : thread_id
    }
type trace_state =
    {
        log_path_probs : tensor (ensemble_id * thread_id * player_id) log_path_prob
    }
type model =
    {
        exploratory_ensemble_id : tensor {} ensemble_id
        rewards : tensor ensemble_id ratio // actual reward is reward / count
        mask : tensor ensemble_id bool // actual reward is reward / count
    }

inl graph (size : sizes) : _ (model * trace_state) =
    open partitionm

    inl model' : partition model =
        !{} *. (!size.ensemble_id *. !size.ensemble_id)
        |> reorder (fun exploratory_ensemble_id,rewards,mask => {exploratory_ensemble_id rewards mask})

    inl trace_state : partition trace_state =
        !(size.ensemble_id, size.thread_id, size.player_id)
        |> reorder (fun log_path_probs => {log_path_probs})

    inl (<|) a b = layers.pair a b
    open layers
    (key_graph .cem_model (layer weight_id() model' (fun x =>
        init_zero x.exploratory_ensemble_id . init_zero x.rewards . init_const x.mask 1
        )))
    <| (key_graph .cem_trace_state (layer workspace_id() trace_state init_zero))

type weights = exists dim. tensor (ensemble_id * dim) float * tensor (dim * ensemble_id) float

// Sets the log_path_probs to 0.
inl reset_trace_state (trace_state : trace_state) =
    open tensorm
    open primitives
    inl thread_id = rangem.threads_in_grid().from
    loop.linear (fst trace_state.log_path_probs.dim) fun ensemble_id =>
        inl log_path_probs = trace_state.log_path_probs |> apply ensemble_id |> apply thread_id
        // Sets the log_path_probs to 0.
        (log_path_probs,log_path_probs) ||> row_gather_map () (fun () config x i j_tns => local_map (const loop.zeroes) x)

// According to CEM papers, adding noise helps performance significantly in games like tetris.
inl cross_entropy_noise() = 0.1
// inl weight_decay() = 0.9
inl weight_decay() = 1

inl calculate_updates forall dim. 
        ({rewards mask} : model) 
        (trace_state : trace_state) 
        (reward : sa dim reward) =
    open tensorm
    inl log_path_probs =
        trace_state.log_path_probs
        |> reorder (fun ensemble_id,thread_id,player_id => thread_id,ensemble_id,player_id)
        |> apply rangem.threads_in_grid().from
        |> apply_ptr
    path_probs.integrate_rewards_over_players log_path_probs (path_probs.sa_to_tensor reward) (Some mask)
    |> iteri (fun ensemble_id (reward, path_prob) =>
        inl path_prob = conv path_prob
        assert (not (nan_is path_prob)) "The path probability after integration should not be a nan in calculate updates."
        tensor_cuda.tensor_atomic_add ensemble_id (reward * path_prob, path_prob) rewards
        )
    reset_trace_state trace_state

// Zeroes out the reward and updates the mask. Needs a grid sync before the updated mask should be read.
inl grid_update_rewards_mask (m : model) =
    inl rewards = tensorm.map (fun reward,count => if count <> 0 then reward / count else 0) m.rewards
    inl average = tensorm.fold 0 (+) rewards / conv (length rewards)
    tensorm.reinit (const loop.zeroes) m.rewards
    tensorm.copy {from = tensorm.map (fun x => x >= average) rewards} m.mask

// Does the CEM update for the weight parameters, 
inl cem forall dim. rng (transposed_weights : tensor (dim * ensemble_id) float) ({mask} : model) =
    grid_row_map' (fun config x i j_tns =>
        open tensorm
        inl mask = local_map (fun ensemble_id => tensor_index ensemble_id mask) j_tns
        inl winner_count = conv (local_masked_count config mask)
        inl winner_mean = local_masked_sum config mask x / winner_count
        inl winner_std =
            inl variance = 
                local_map (fun x => inl r = x - winner_mean in r * r) x
                |> local_masked_sum config mask
                |> fun x => x / winner_count
            inl biased_std = sqrt variance
            if winner_count > 1 then biased_std * winner_count / (winner_count - 1) else 0
        local_map (fun x,b => 
            inl r = (conv (random.normal rng) * (max winner_std cross_entropy_noise()) + winner_mean) * weight_decay()
            if b then x else r
            ) (tensorm.zip x mask)
        ) transposed_weights transposed_weights

inl apply_updates rng grid (weights : list weights) (model : model) : () =
    cooperative_groups.sync grid // TODO: Get rid of the grid sync on this line here. It needs to be moved to a better location.

    if rangem.threads_in_grid().from = 0 then // We want to only change the id after all the threads have finished running the game.
        tensorm.tensor_set {} (random.int_range {from=0; nearTo=model.rewards.dim} rng) model.exploratory_ensemble_id // Pick a random ensemble id
    __syncwarp() // Converge the first warp.

    grid_update_rewards_mask model
    weights |> listm.iter fun (exists dim. weights, transposed_weights) =>
        grid_transpose weights transposed_weights

    cooperative_groups.sync grid

    weights |> listm.iter fun (exists dim. _, transposed_weights) =>
        cem rng transposed_weights model

    cooperative_groups.sync grid

    // prints out the weight norms.
    weights |> listm.iter fun (exists dim. weights, transposed_weights) =>
        inl norms : tensor dim float = tensor_cuda.tensor_create_static (fst transposed_weights.dim)
        primitives.grid_map_reduce_map_2d grid sqr 0 (+) sqrt transposed_weights norms
        primitives.grid_reduce grid 0 max norms
        |> fun max_norm => print0 {max_norm}

    weights |> listm.iter fun (exists dim. weights, transposed_weights) =>
        grid_transpose transposed_weights weights
    
    cooperative_groups.sync grid
        

open layers
open tensorm

inl get_action rng model ensemble_id =
    // Extract the output probabilities (already calculated.)
    inl output_probs = (key_extract model .output_probs : tensor d4 float)

    open primitives
    output_probs
    |> apply ensemble_id
    |> apply block_index()
    |> apply thread_index()
    |> row_gather_reduce rng (fun rng config policy_probs i j_tns =>
        inl action_id = local_discrete_sampling rng config policy_probs i j_tns
        local_get_prob config action_id (zip policy_probs j_tns), action_id
        )

// Returns policy probability of an action given the ensemble_id and the action_id.
// If the first argument is true, it does that using the `policy.current` else it uses `policy.average`.
inl get_policy_probs model ensemble_id action_id =
    // Extract the output probabilities (already calculated.)
    inl output_probs = (key_extract model .output_probs : tensor d4 float)
    tensor_index (ensemble_id, block_index(), thread_index(), action_id) output_probs

// Updates the trace state log path probabilities.
inl push_trace (trace_state : trace_state) {thread_id ensemble_id player_id} (action_prob, action_id : action_prob * action_id) : () =
    // Updates the log path probs in the trace_state.
    inl v = {
        sampling = log (conv action_prob.sampling)
        policy = log (conv action_prob.policy)
    }

    // Updates the log path probs in the trace_state.
    tensor_update (ensemble_id, thread_id, player_id) (fun x => 
        inl x = loop.add v x
        assert (not (nan_is x.sampling)) "The sampling log probability shouldn't be nan."
        assert (not (nan_is x.policy)) "The policy log probability shouldn't be nan."
        x
        ) trace_state.log_path_probs

// Updates the trace state log path probabilities.
inl update_trace_state_path_probs x = push_trace x
