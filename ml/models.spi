open corebase
open coreext
open layers
open tensorm

type size = // The block and thread dimensions should match blocks_per_grid and threads_per_block
    {
        ensemble : int
    }

open corecuda
open rangem
inl run' forall inp out.
        (exists t. model : exists t. model t) 
        (exists mid. input : exists mid. (inp -> mid) * pickler.pu mid) 
        (output : int -> out) 
        ~(data : option inp) = join
    console.write_ln {tid_before=thread_index()}
    
    // All the threads will be waiting on this barrier until the game threads call on it with the inputs.
    __syncthreads()

    console.write_ln {tid_after=thread_index()}

    // Get the ensemble,block and thread dimensions based on the output tensor.
    inl ensemble,block,thread,inner = (key_extract model .output_probs : tensor d4 float).dim
    inl () = // Assert that all the dimensions are right.
        assert (block = blocks_per_grid()) "The second dimension of the output tensor has to equal the number of blocks per grid."
        assert (thread = threads_per_block()) "The third dimension of the output tensor has to equal number threads per block."
        inl block',thread',_ = (key_extract model .input : tensor d3 float).dim
        assert ((block,thread) = (block',thread')) "The first two dimensions of the input tensor have to match number of blocks per grid and number of threads per block respectively."
        inl ensemble',block',thread' = (key_extract model .output_indices : tensor d3 int).dim
        assert ((ensemble,block,thread) = (ensemble',block',thread')) "The dimensions of the output indices tensor have to match."

    // Creates the layer state.
    inl ls = create_layer_state()

    // Extract the input tensor.
    inl x = (key_extract model .input : tensor d3 float)
    assert (block = fst x.dim) "The first dimension of the input tensor has to equal the number of blocks per grid."
    inl x = x |> apply block_index()
    assert (thread = fst x.dim) "The second dimension of the input tensor has to equal number threads per block."

    // Creates the layer state.
    inl ls = create_layer_state()

    // Sets the input tensor to 0.
    loop.projective threads_in_block(x.dim) fun i =>
        tensor_set i 0 x

    __syncthreads()

    // Serializes the data into the input tensor if there is any data being passed into the model.
    // If there is no data being passed into run here, the individual threads for which that is the case can 
    // still contribute by doing computation. They contribute to the functioning of the entire block.
    data |> optionm.iter fun data =>
        open pickler
        inl tns_input = apply thread_index() x
        snd input .pickle (fst input data) (0,tns_input |> ptr_at_current_offset)

    __syncthreads()

    // Runs the model on the inputs.
    loop.linear ensemble fun ensemble =>
        graph_run_device model ls {ensemble}

    __syncthreads()

    // Randomly pick an ensemble id for each thread.
    inl ensemble_id : int = random.int_range {from=0; nearTo=ensemble} ls.rng

    // Extract the output probabilities (already calculated).
    inl output_probs = (key_extract model .output_probs : tensor d4 float) 

    // Extract the output index.
    inl output_id =
        (key_extract model .output_indices : tensor d3 int) 
        |> apply ensemble_id
        |> apply block_index()
        |> tensor_index thread_index()

    {
        action = output output_id
        sampling_prob_selected = output_probs |> tensor_index (ensemble_id,block_index(),thread_index(),output_id)
        sampling_prob_ensemble =
            output_probs
            |> reorder (fun ensemble,block,thread,inner => block,thread,inner,ensemble)
            |> apply block_index() |> apply thread_index() |> apply output_id
    }

nominal game_graph inp out =
    {
        graph : exists mid. graph mid
        input : exists t. (inp -> t) * pickler.pu t
        output : int -> out
    }

nominal game_model inp out = 
    {
        model : exists mid. model mid
        input : exists t. (inp -> t) * pickler.pu t
        output : int -> out
    }

inl run forall inp out. (game_model {model input output} : game_model inp out) = run' model input output

inl to_model_data forall a b. (game_model {model=exists t. model} : game_model a b) : layers.model_data = model_to_model_data model
inl from_model_data forall inp out. 
        (game_graph {graph=(exists t. graph) input output} : game_graph inp out) 
        (x : layers.model_data) 
        : game_model inp out = 
    inl model : exists t. model t = exists model_data_to_model graph x
    game_model {model input output}

inl init forall a b. (game_graph {graph=(exists t. graph) input output} : game_graph a b) : game_model a b = 
    inl model = create_model graph
    param_init model
    game_model { input output model = exists model }

// Returns the amount of shared memory being used by the graph.
inl smem_used (game_graph {graph=exists t. graph}) : int = pass_calculate_dynamic_shared_memory graph |> conv