open corebase
open tensorm
open compile_time

type ptr = partitionm.ptr
type size = partitionm.size

union rec graph t =
    | Matmul : graph t * graph t
    | Map : graph t
    | Map2 : graph t * graph t
    | Input : {key : exists key{symbol}. key}
    | Weight : {dim : int * int}

type dim = int * int

inl memoize (h : .hashmap) f k =
    match hashmap.try_get h k with
    | Some v => v
    | None => inl v = f k in hashmap.add h k v . v

inl pass_dim forall t dims. (x : graph t) (dims : dims) =
    inl h = hashmap.create()
    inl get_dim forall k{symbol}. (k : k) : dim = real dims k : dim
    inl rec f forall t'. :  graph t' -> dim =
        memoize h function
            | Weight {dim} => dim
            | Input {key=(exists k. k)} => get_dim k
            | Map(a) => f a
            | Map2(a,b) =>
                inl a,b = f a, f b
                assert (a = b) "The dimensions of the two inputs to the Map2 node have to be equal."
                a
            | Matmul(a,b) =>
                inl (m,k),(k',n) = f a, f b
                assert (k = k') "The dimensions of the inner dimensions to the matrix multiplication node have to be equal."
                m,n
            
    inl _ = f x
    h

inl pass_offset_param forall t. (x : graph t) (dims : .hashmap) =
    inl h_offset_param = hashmap.create() // stores the offsets pointing to the start of the weight parameter array for each node
    inl h = hashmap.create()
    inl get_dim forall k. (k : k) : dim = match hashmap.try_get dims k with Some v => v | None => error_type "Cannot get the node dimension from the dictionary."
    inl rec f forall t'. (offset : size) : graph t' -> size =
        memoize h function
            | Weight _ as k =>
                inl partition_offsets : _ (_ _ t') = 
                    partitionm.to_partition(get_dim k)
                    |> partitionm.calculate_offsets offset 
                hashmap.add h_offset_param k partition_offsets
                partition_offsets.offset_end
            | Input _ => offset
            | Map(a) => f offset a
            | Matmul(a,b) | Map2(a,b) => f (f offset a) b
    h_offset_param, f 0 x

inl pass_offset_input forall t. (x : graph t) (dims : .hashmap) =
    inl h_offset_input = hashmap.create() // stores the offsets pointing to the start of the output array for each node
    inl h = hashmap.create()
    inl get_dim forall k. (k : k) : dim = match hashmap.try_get dims k with Some v => v | None => error_type "Cannot get the node dimension from the dictionary."
    inl rec f forall t'. (offset : size) : graph t' -> size =
        memoize h fun k =>
            inl g (offset : size) = // during graph execution we'll get the offsets for the input nodes from the `h_offset_input` hash map, no need to store them here
                inl partition_offsets : _ (_ _ t') = 
                    partitionm.to_partition(get_dim k)
                    |> partitionm.calculate_offsets offset 
                hashmap.add h_offset_input k partition_offsets
                partition_offsets.offset_end
            match k with
            | Weight _ => offset
            | Input _ => g offset
            | Map(a) => g (f offset a)
            | Matmul(a,b) | Map2(a,b) => g (f (f offset a) b)

    h_offset_input, f 0 x

type graph_env_param =
    {
        dims : .hashmap
        offset_param : .hashmap * size
    }

inl weigth_init forall float. base_and_length (x : graph float) ({dims offset_param=h,size} : graph_env_param) =
    inl rec f forall t. (x : graph t) : () =
        match x with
        | Weight _ =>
            open corecuda
            inl x : tensor dim t = partitionm.from_partition_offsets base_and_length (hashmap.get h x)
            cupy.copy_to {from=cupy.random_normal{mean=0; std=1} x.dim; to=x}
        | Input => ()
        | Map(a) => f a
        | Matmul(a,b) | Map2(a,b) => f a . f b
    f x

inl test1() =
    inl tanh x = Map x
    inl matmul dim x = Matmul(x, Weight {dim})
    inl input forall key{symbol}. (key : key) = Input {key = exists key}

    inl layers : graph float =
        input .input
        |> matmul (64, 128)
        |> tanh
        |> matmul (128, 128)
        |> tanh
        |> matmul (128, 32)
        |> tanh
    
    inl dims = {input = 1, 64 : int * int}
    inl h = pass_dim layers dims
    compile_time.hashmap.try_get h layers : option (int * int)

inl main() = test1()